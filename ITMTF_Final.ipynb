{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imports for Parsing\n",
    "'''\n",
    "import os\n",
    "import tarfile\n",
    "import xml.dom.minidom\n",
    "import pandas as pd\n",
    "from xml.etree import cElementTree as ET\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "'''\n",
    "Imports for Algorithm\n",
    "'''\n",
    "import nltk; \n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "# causalty measure\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETURN: Array of tuples containing date and doc content\n",
    "# [(date, document_content)]\n",
    "def get_timestamped_docs():\n",
    "    docs = [] #(date, document_data)\n",
    "    for month in os.listdir(\"./documents\"):\n",
    "        for day in os.listdir(\"./documents/\"+month):\n",
    "            for doc in os.listdir(\"./documents/\"+month+\"/\"+day):\n",
    "                tree = ET.parse(\"./documents/\"+month+\"/\"+day+\"/\"+doc)\n",
    "                root = tree.getroot()\n",
    "                for page in root.findall('body'):\n",
    "                    for page1 in page.findall('body.content'):\n",
    "                        for page2 in page1.findall('block'):\n",
    "                            for page3 in page2.findall('p'):\n",
    "                                if page3.text != None:\n",
    "                                    docs.append((month+\"/\"+day+\"/00\", page3.text)) \n",
    "            break\n",
    "        break\n",
    "    return docs\n",
    "        \n",
    "# RETURN: documents that contain \"Gore\" or \"Bush\" \n",
    "# documents: [String], timestamps: [String] \n",
    "def filter_docs(docs):\n",
    "    D = [] # document contents \n",
    "    T = [] # corresponding timestamps for documents\n",
    "    for i, doc in enumerate(docs):\n",
    "        gore = 0\n",
    "        bush = 0\n",
    "        if \"Gore\" in doc[1]:\n",
    "            gore += 1\n",
    "        if \"Bush\" in doc[1]:\n",
    "            bush += 1\n",
    "        if gore > 0 or bush > 0:\n",
    "            T.append(doc[0])\n",
    "            D.append(doc[1])\n",
    "    return (D, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_timestamped_docs()\n",
    "D, T = filter_docs(docs) # returns documents and their timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Initial Pass (Generate Topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['choose', 'southern', 'state', 'backdrop', 'conservative', 'speech', 'presidential', 'campaign', 'mr', 'gore', 'propose', 'federal', 'spending', 'year', 'help', 'state', 'test', 'treat', 'counsel', 'prisoner', 'parole', 'drug']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('backdrop', 1),\n",
       "  ('campaign', 1),\n",
       "  ('choose', 1),\n",
       "  ('conservative', 1),\n",
       "  ('counsel', 1),\n",
       "  ('drug', 1),\n",
       "  ('federal', 1),\n",
       "  ('gore', 1),\n",
       "  ('help', 1),\n",
       "  ('mr', 1),\n",
       "  ('parole', 1),\n",
       "  ('presidential', 1),\n",
       "  ('prisoner', 1),\n",
       "  ('propose', 1),\n",
       "  ('southern', 1),\n",
       "  ('speech', 1),\n",
       "  ('spending', 1),\n",
       "  ('state', 2),\n",
       "  ('test', 1),\n",
       "  ('treat', 1),\n",
       "  ('year', 1)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference from https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "# removing punctuations and unnecessary characters altogether\n",
    "def sent_to_words(sentences):\n",
    "    #print(sentences)\n",
    "    for sentence in sentences:\n",
    "        #print(sentence[1])\n",
    "        yield(gensim.utils.simple_preprocess(str(sentences[1]), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(D))\n",
    "\n",
    "# Step 9\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "# print(trigram_mod[bigram_mod[data_words[0]]])\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "# Step 10\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#print(download('en'))\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) \n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])\n",
    "\n",
    "#Step 11\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "#print(corpus[:1])\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.048*\"presidential\" + 0.048*\"parole\" + 0.048*\"treat\" + 0.048*\"test\" + '\n",
      "  '0.048*\"state\" + 0.048*\"spending\" + 0.048*\"speech\" + 0.048*\"southern\" + '\n",
      "  '0.048*\"propose\" + 0.048*\"prisoner\"'),\n",
      " (1,\n",
      "  '0.091*\"state\" + 0.045*\"campaign\" + 0.045*\"spending\" + 0.045*\"presidential\" '\n",
      "  '+ 0.045*\"mr\" + 0.045*\"help\" + 0.045*\"speech\" + 0.045*\"treat\" + 0.045*\"year\" '\n",
      "  '+ 0.045*\"test\"'),\n",
      " (2,\n",
      "  '0.048*\"spending\" + 0.048*\"federal\" + 0.048*\"test\" + 0.048*\"presidential\" + '\n",
      "  '0.048*\"southern\" + 0.048*\"counsel\" + 0.048*\"propose\" + 0.048*\"year\" + '\n",
      "  '0.048*\"state\" + 0.048*\"mr\"'),\n",
      " (3,\n",
      "  '0.048*\"state\" + 0.048*\"drug\" + 0.048*\"backdrop\" + 0.048*\"propose\" + '\n",
      "  '0.048*\"southern\" + 0.048*\"conservative\" + 0.048*\"counsel\" + 0.048*\"choose\" '\n",
      "  '+ 0.048*\"spending\" + 0.048*\"gore\"'),\n",
      " (4,\n",
      "  '0.048*\"presidential\" + 0.048*\"parole\" + 0.048*\"treat\" + 0.048*\"test\" + '\n",
      "  '0.048*\"state\" + 0.048*\"spending\" + 0.048*\"speech\" + 0.048*\"southern\" + '\n",
      "  '0.048*\"propose\" + 0.048*\"prisoner\"'),\n",
      " (5,\n",
      "  '0.048*\"state\" + 0.048*\"drug\" + 0.048*\"year\" + 0.048*\"propose\" + '\n",
      "  '0.048*\"prisoner\" + 0.048*\"choose\" + 0.048*\"campaign\" + 0.048*\"counsel\" + '\n",
      "  '0.048*\"southern\" + 0.048*\"backdrop\"'),\n",
      " (6,\n",
      "  '0.048*\"state\" + 0.048*\"gore\" + 0.048*\"federal\" + 0.048*\"southern\" + '\n",
      "  '0.048*\"backdrop\" + 0.048*\"drug\" + 0.048*\"conservative\" + 0.048*\"parole\" + '\n",
      "  '0.048*\"counsel\" + 0.048*\"presidential\"'),\n",
      " (7,\n",
      "  '0.048*\"state\" + 0.048*\"campaign\" + 0.048*\"prisoner\" + 0.048*\"treat\" + '\n",
      "  '0.048*\"speech\" + 0.048*\"propose\" + 0.048*\"conservative\" + 0.048*\"parole\" + '\n",
      "  '0.048*\"drug\" + 0.048*\"mr\"'),\n",
      " (8,\n",
      "  '0.048*\"state\" + 0.048*\"propose\" + 0.048*\"gore\" + 0.048*\"speech\" + '\n",
      "  '0.048*\"federal\" + 0.048*\"parole\" + 0.048*\"choose\" + 0.048*\"campaign\" + '\n",
      "  '0.048*\"test\" + 0.048*\"treat\"'),\n",
      " (9,\n",
      "  '0.048*\"state\" + 0.048*\"campaign\" + 0.048*\"year\" + 0.048*\"prisoner\" + '\n",
      "  '0.048*\"spending\" + 0.048*\"counsel\" + 0.048*\"help\" + 0.048*\"presidential\" + '\n",
      "  '0.048*\"conservative\" + 0.048*\"backdrop\"')]\n"
     ]
    }
   ],
   "source": [
    "# Step 12: setup LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=NUM_TOPICS, \n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=50,\n",
    "                                           alpha='auto')\n",
    "\n",
    "#Step 13\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -3.077459966137108\n",
      "\n",
      "Coherence Score:  0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Step 14\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Iowa Electronic Markets (IEM) Timeseries Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_df = pd.read_csv(\"timeSeriesPrices.csv\")\n",
    "\n",
    "# convert $Volume column to float64\n",
    "tsp_df[\"$Volume\"] = tsp_df[\"$Volume\"].apply(lambda x: x.replace(',', ''))\n",
    "tsp_df[\"$Volume\"] = tsp_df[\"$Volume\"].astype(float)\n",
    "tsp_df[\"$Volume\"].loc[tsp_df[\"$Volume\"] == 0] = 0.001 # replace zero values\n",
    "\n",
    "# setup normalized_tsp_df. each index is a day from 05/01/00 to 10/31/00\n",
    "gore_prices = tsp_df.loc[tsp_df.Contract == \"Dem\"][\"$Volume\"].reset_index(drop=True)\n",
    "bush_prices = tsp_df.loc[tsp_df.Contract == \"Rep\"][\"$Volume\"].reset_index(drop=True)\n",
    "normalized_tsp_df = gore_prices / (bush_prices + gore_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(pvalue):\n",
    "    return 1 - pvalue\n",
    "\n",
    "def get_max_significance_key(gc_res):\n",
    "    max_key = 1\n",
    "    max_val = -1\n",
    "    for key in gc_res.keys():\n",
    "        if gc_res[key][0]['params_ftest'][0] > max_val:\n",
    "            max_key = key\n",
    "            max_val = gc_res[key][0]['params_ftest'][0]\n",
    "    return max_key\n",
    "\n",
    "def setup_topic_stream(lda_corpus, timestamps):\n",
    "    document_topic_coverages = []\n",
    "    topic_coverage = [0 for i in range(NUM_TOPICS)]\n",
    "    for i, coverage in enumerate(lda_corpus):\n",
    "        for j, topic in enumerate(coverage):\n",
    "            topic_coverage[topic[0]] = topic[1]\n",
    "        document_topic_coverages.append([timestamps[i]] + topic_coverage)\n",
    "        topic_coverage = [0 for i in range(NUM_TOPICS)]\n",
    "    \n",
    "    # set up dataframe\n",
    "    fields = [\"Date\"] + [\"Topic\"+str(i) for i in range(NUM_TOPICS)]\n",
    "    topic_stream_df = pd.DataFrame(document_topic_coverages, columns=fields)\n",
    "    return topic_stream_df\n",
    "\n",
    "def get_candidate_causal_topics(topic_stream_df, tsp_df, gamma):\n",
    "    CT = []\n",
    "    topic_list = [\"Topic\"+str(i) for i in range(NUM_TOPICS)]\n",
    "    for i, topic in enumerate(topic_list):\n",
    "        x = np.array([topic_stream_df[topic].tolist(), normalized_tsp_df.tolist()]).T # TODO: MAY HAVE TO SWITCH THESE\n",
    "        gc_res = grangercausalitytests(x, 5)\n",
    "        key = get_max_significance_key(gc_res)\n",
    "        pvalue = gc_res[key][0]['params_ftest'][1]\n",
    "        significance = sig(pvalue)\n",
    "        if significance > gamma:\n",
    "            CT.append(topic)\n",
    "    return CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05/03/00</th>\n",
       "      <td>0</td>\n",
       "      <td>76.7555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Topic0   Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  \\\n",
       "Date                                                                        \n",
       "05/03/00       0  76.7555       0       0       0       0       0       0   \n",
       "\n",
       "          Topic8  Topic9  \n",
       "Date                      \n",
       "05/03/00       0       0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2\n",
    "lda_corpus = lda_model[corpus] # setup the topic coverage for each document\n",
    "topic_stream_df = setup_topic_stream(lda_corpus, T)\n",
    "topic_stream_df = topic_stream_df.groupby(\"Date\").sum()\n",
    "topic_stream_df\n",
    "# CT = get_candidate_causal_topics(topic_stream_df, normalized_tsp_df, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3\n",
    "'''\n",
    "For each candidate topic in CT, apply C to find the mostsignificant causal words among top wordsw∈T. \n",
    "Recordthe impact values of these significant words (e.g., word-levelPearson correlations with the time series variable)\n",
    "'''\n",
    "def setup_wordcount_stream(timestamps):\n",
    "    words = [[id2word[id] for id, freq in cp] for cp in corpus[:1]][0]\n",
    "    df_rows = []\n",
    "    for i, doc in enumerate(D):\n",
    "        wordcount_dict = {word: 0  for i, word in enumerate(words)} \n",
    "        for word in doc.lower().split(\" \"):\n",
    "            if (word.lower() in wordcount_dict):\n",
    "                wordcount_dict[word] += 1\n",
    "        df_rows.append([timestamps[i]] + [val for val in wordcount_dict.values()])\n",
    "    \n",
    "    # set up dataframe\n",
    "    fields = [\"Date\"] + [words[i] for i in range(len(words))]\n",
    "    wordcount_stream_df = pd.DataFrame(df_rows, columns=fields)\n",
    "    return wordcount_stream_df\n",
    "\n",
    "\n",
    "# return array [(word, impact_value)]\n",
    "def get_significant_causal_topics(wordcount_stream_df, tsp_df, gamma):\n",
    "    impact_values = []\n",
    "    words = [[id2word[id] for id, freq in cp] for cp in corpus[:1]][0]\n",
    "    for i, word in enumerate(words):\n",
    "        x = np.array([wordcount_stream_df[word].tolist(), tsp_df.tolist()]).T\n",
    "#         gc_res = grangercausalitytests(x, 5)\n",
    "#         key = get_max_significance_key(gc_res)\n",
    "#         pvalue = gc_res[key][0]['params_ftest'][1]\n",
    "#         significance = sig(pvalue)\n",
    "#         if significance > gamma:\n",
    "#             SCT.append(word)\n",
    "        pvalue = sp.stats.pearsonr(x, tsp_df)\n",
    "        significance = sig(pvalue)\n",
    "        if significance > gamma:\n",
    "            impact_values.append((word, pvalue))\n",
    "    return impact_values \n",
    "    \n",
    "    \n",
    "#     CT = []\n",
    "#     topic_list = [\"Topic\"+str(i) for i in range(NUM_TOPICS)]\n",
    "#     for i, topic in enumerate(topic_list):\n",
    "#         x = np.array([topic_stream_df[topic].tolist(), normalized_tsp_df.tolist()]).T # TODO: MAY HAVE TO SWITCH THESE\n",
    "#         gc_res = grangercausalitytests(x, 5)\n",
    "#         key = get_max_significance_key(gc_res)\n",
    "#         pvalue = gc_res[key][0]['params_ftest'][1]\n",
    "#         significance = sig(pvalue)\n",
    "#         if significance > gamma:\n",
    "#             CT.append(topic)\n",
    "#     return CT\n",
    "     \n",
    "# # One is the external time series (e.g. prices) \n",
    "# #and the other is the sum of word counts per time-stamp. You can find more details in section 4.2.2 \n",
    "# for topic in CT:\n",
    "#     # apply C\n",
    "#     break\n",
    "\n",
    "\n",
    "wordcount_stream_df = setup_wordcount_stream(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.659104\n",
       "1      0.372295\n",
       "2      0.645607\n",
       "3      0.286292\n",
       "4      0.739999\n",
       "5      0.242304\n",
       "6      0.000094\n",
       "7      0.130042\n",
       "8      0.363381\n",
       "9      0.438038\n",
       "10     0.450395\n",
       "11     0.743199\n",
       "12     0.544253\n",
       "13     0.999332\n",
       "14     0.497994\n",
       "15     0.587027\n",
       "16     0.591153\n",
       "17     0.588401\n",
       "18     0.359324\n",
       "19     0.986226\n",
       "20     0.357826\n",
       "21     0.616880\n",
       "22     0.762738\n",
       "23     0.745276\n",
       "24     0.031323\n",
       "25     0.716387\n",
       "26     0.323849\n",
       "27     0.998128\n",
       "28     0.999923\n",
       "29     0.033904\n",
       "         ...   \n",
       "152    0.633310\n",
       "153    0.399007\n",
       "154    0.655756\n",
       "155    0.659162\n",
       "156    0.408249\n",
       "157    0.304458\n",
       "158    0.587465\n",
       "159    0.645196\n",
       "160    0.493369\n",
       "161    0.346190\n",
       "162    0.599063\n",
       "163    0.515088\n",
       "164    0.214619\n",
       "165    0.389410\n",
       "166    0.308602\n",
       "167    0.588639\n",
       "168    0.859825\n",
       "169    0.470041\n",
       "170    0.717222\n",
       "171    0.490814\n",
       "172    0.371428\n",
       "173    0.430711\n",
       "174    0.519166\n",
       "175    0.571434\n",
       "176    0.532200\n",
       "177    0.484197\n",
       "178    0.371508\n",
       "179    0.363610\n",
       "180    0.542174\n",
       "181    0.303600\n",
       "Name: $Volume, Length: 182, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tsp_df\n",
    "# words = [[id2word[id] for id, freq in cp] for cp in corpus[:1]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([id2word.doc2bow(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=28.7248 , p=0.0000  , df_denom=198, df_num=1\n",
      "ssr based chi2 test:   chi2=29.1600 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=27.2295 , p=0.0000  , df=1\n",
      "parameter F test:         F=28.7248 , p=0.0000  , df_denom=198, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=18.9880 , p=0.0000  , df_denom=195, df_num=2\n",
      "ssr based chi2 test:   chi2=38.9498 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=35.5873 , p=0.0000  , df=2\n",
      "parameter F test:         F=18.9880 , p=0.0000  , df_denom=195, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=13.5015 , p=0.0000  , df_denom=192, df_num=3\n",
      "ssr based chi2 test:   chi2=41.9812 , p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=38.0914 , p=0.0000  , df=3\n",
      "parameter F test:         F=13.5015 , p=0.0000  , df_denom=192, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=10.9646 , p=0.0000  , df_denom=189, df_num=4\n",
      "ssr based chi2 test:   chi2=45.9467 , p=0.0000  , df=4\n",
      "likelihood ratio test: chi2=41.3192 , p=0.0000  , df=4\n",
      "parameter F test:         F=10.9646 , p=0.0000  , df_denom=189, df_num=4\n"
     ]
    }
   ],
   "source": [
    "data = sm.datasets.macrodata.load_pandas()\n",
    "data = data.data[[\"realgdp\", \"realcons\"]].pct_change().dropna()\n",
    "gc_res = grangercausalitytests(data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "def generate_prior(significance):\n",
    "    \n",
    "    #Define a prior on the topic model parameters using significant terms and their impact values. \n",
    "    #Step 4a\n",
    "    pos_impact = [sig - .90 for sig in significance]\n",
    "    neg_impact = [-sig - .90 for sig in significance]\n",
    "    for i, sig in enumerate(pos_impact):\n",
    "        if sig < 0:\n",
    "            pos_impact[i] = 0\n",
    "            \n",
    "    for i, sig in enumerate(neg_impact):\n",
    "        if sig < 0:\n",
    "            neg_impact[i] = 0\n",
    "        \n",
    "    pos_impact = numpy.array(pos_impact)\n",
    "    neg_impact = numpy.array(neg_impact)\n",
    "    \n",
    "    prior = []\n",
    "    for i in range(len(pos_impact)):\n",
    "        count_pos = np.count_nonzero(positive_sigs)\n",
    "        count_neg = np.count_nonzero(negative_sigs)\n",
    "        sum_impact = count_pos + count_neg\n",
    "        if sum_impact != 0:\n",
    "            prob = count_pos / sum_impact\n",
    "            #step 4b\n",
    "            if (prob > 0.9):\n",
    "                prior.append(pos_impact / np.sum(pos_impact))\n",
    "            elif (prob < 0.1):\n",
    "                prior.append(neg_impact / np.sum(neg_impact))\n",
    "            else:\n",
    "                prior.append(pos_impact / np.sum(pos_impact))\n",
    "                prior.append(neg_impact / np.sum(neg_impact))                \n",
    "    \n",
    "    if prior != None:\n",
    "        return numpy.array(prior)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.048*\"state\" + 0.048*\"choose\" + 0.048*\"presidential\" + 0.048*\"counsel\" + '\n",
      "  '0.048*\"mr\" + 0.048*\"drug\" + 0.048*\"spending\" + 0.048*\"southern\" + '\n",
      "  '0.048*\"prisoner\" + 0.048*\"help\"'),\n",
      " (1,\n",
      "  '0.050*\"state\" + 0.048*\"choose\" + 0.048*\"speech\" + 0.048*\"help\" + '\n",
      "  '0.048*\"federal\" + 0.048*\"spending\" + 0.048*\"presidential\" + '\n",
      "  '0.048*\"backdrop\" + 0.048*\"southern\" + 0.048*\"campaign\"'),\n",
      " (2,\n",
      "  '0.049*\"state\" + 0.048*\"parole\" + 0.048*\"choose\" + 0.048*\"treat\" + '\n",
      "  '0.048*\"help\" + 0.048*\"propose\" + 0.048*\"spending\" + 0.048*\"year\" + '\n",
      "  '0.048*\"presidential\" + 0.048*\"test\"'),\n",
      " (3,\n",
      "  '0.087*\"state\" + 0.047*\"presidential\" + 0.046*\"gore\" + 0.046*\"help\" + '\n",
      "  '0.046*\"conservative\" + 0.046*\"year\" + 0.046*\"drug\" + 0.046*\"prisoner\" + '\n",
      "  '0.046*\"choose\" + 0.046*\"parole\"'),\n",
      " (4,\n",
      "  '0.054*\"state\" + 0.048*\"propose\" + 0.048*\"parole\" + 0.048*\"mr\" + '\n",
      "  '0.048*\"choose\" + 0.048*\"campaign\" + 0.048*\"gore\" + 0.048*\"treat\" + '\n",
      "  '0.048*\"test\" + 0.047*\"prisoner\"'),\n",
      " (5,\n",
      "  '0.059*\"state\" + 0.049*\"test\" + 0.048*\"treat\" + 0.048*\"backdrop\" + '\n",
      "  '0.048*\"mr\" + 0.048*\"speech\" + 0.048*\"federal\" + 0.047*\"choose\" + '\n",
      "  '0.047*\"propose\" + 0.047*\"campaign\"'),\n",
      " (6,\n",
      "  '0.091*\"state\" + 0.045*\"backdrop\" + 0.045*\"propose\" + 0.045*\"treat\" + '\n",
      "  '0.045*\"southern\" + 0.045*\"test\" + 0.045*\"drug\" + 0.045*\"campaign\" + '\n",
      "  '0.045*\"counsel\" + 0.045*\"federal\"'),\n",
      " (7,\n",
      "  '0.048*\"state\" + 0.048*\"mr\" + 0.048*\"parole\" + 0.048*\"gore\" + '\n",
      "  '0.048*\"propose\" + 0.048*\"drug\" + 0.048*\"campaign\" + 0.048*\"southern\" + '\n",
      "  '0.048*\"test\" + 0.048*\"backdrop\"'),\n",
      " (8,\n",
      "  '0.048*\"mr\" + 0.048*\"help\" + 0.048*\"choose\" + 0.048*\"prisoner\" + '\n",
      "  '0.048*\"backdrop\" + 0.048*\"presidential\" + 0.048*\"campaign\" + 0.048*\"treat\" '\n",
      "  '+ 0.048*\"parole\" + 0.048*\"test\"'),\n",
      " (9,\n",
      "  '0.048*\"parole\" + 0.048*\"mr\" + 0.048*\"state\" + 0.048*\"treat\" + '\n",
      "  '0.048*\"choose\" + 0.048*\"conservative\" + 0.048*\"speech\" + 0.048*\"propose\" + '\n",
      "  '0.048*\"counsel\" + 0.048*\"campaign\"')]\n"
     ]
    }
   ],
   "source": [
    "#step 6\n",
    "iteration = 0\n",
    "iteration_num = 10\n",
    "\n",
    "while iteration < iteration_num:\n",
    "    iteration += 1\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=NUM_TOPICS, \n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto')\n",
    "    \n",
    "    sigTopics = lda_model.get_topics()\n",
    "    topic_prior = generate_prior(sigTopics)\n",
    "    doc_lda = lda_model[corpus]\n",
    "    \n",
    "pprint(lda_model.print_topics())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
